{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p4j2IensPquE"
   },
   "source": [
    "# **Importing required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xFgW-pO7Pv-e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ztpybZPWQMce"
   },
   "source": [
    "### Convert BGR to RGB to ensure colors are properly passed for displaying images using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RelQLP3LQYmZ"
   },
   "outputs": [],
   "source": [
    "def colorConvert(image):\n",
    "  return(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3QMKzxz5TJvm"
   },
   "source": [
    "# **Extract Background in Video Input**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHkUJf7FZrUk"
   },
   "source": [
    "### Capturing the Video in 'cap' and extract 30 random frames and store the selected frames in an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tGP0f2IwTOXP"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Media/vtest.avi')\n",
    "\n",
    "#Randomly selecting 30 frames\n",
    "frame_get = cap.get(cv2.CAP_PROP_FRAME_COUNT) * np.random.uniform(size = 30)\n",
    "\n",
    "#Storing captured frames in an array\n",
    "frames = []\n",
    "for i in frame_get:\n",
    "  cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "  ret, frame = cap.read()\n",
    "  frames.append(frame)\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFOPGwsobbqE"
   },
   "source": [
    "### Calculating median and average frames, for better outlier removal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "Kt-B-2wrbpAM",
    "outputId": "289cd8a9-8a34-4d1c-ad3e-ce18a77f82b2"
   },
   "outputs": [],
   "source": [
    "frame_median = np.median(frames, axis = 0).astype(dtype = np.uint8)\n",
    "plt.imshow(colorConvert(frame_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "7Zt0Pd45alSm",
    "outputId": "ed4a3dcc-bd7d-4a52-db42-10bc26a50ec7"
   },
   "outputs": [],
   "source": [
    "frame_avg = np.average(frames, axis = 0).astype(dtype = np.uint8)\n",
    "plt.imshow(colorConvert(frame_avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qv94Q9v8bEfs"
   },
   "source": [
    "# **Processing a Frame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rs1-738_btUf"
   },
   "source": [
    "### Studying a single frame separately (first frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "LpBPd_CBbIWF",
    "outputId": "ce0a4251-25d4-4b0c-f469-8902e4111459"
   },
   "outputs": [],
   "source": [
    "frame_sample = frames[0]\n",
    "plt.imshow(colorConvert(frame_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKWd-s-fb8im"
   },
   "source": [
    "We see a number of moving objects here (people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sOeyhpt9cGit"
   },
   "source": [
    "## **Converting the Median and sample image to grayscale**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "b7lDKlnCcPDx",
    "outputId": "aae74a6b-297a-47bc-d865-62a180b20bdf"
   },
   "outputs": [],
   "source": [
    "gray_frame_median = cv2.cvtColor(frame_median, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(colorConvert(gray_frame_median))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "ibz0G9Blctk9",
    "outputId": "c6a4d5eb-9830-4d07-c0c1-5e3bf95ae83a"
   },
   "outputs": [],
   "source": [
    "gray_frame_sample = cv2.cvtColor(frame_sample, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(colorConvert(gray_frame_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPIwmmcjeuCF"
   },
   "source": [
    "# **Background Removal**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPMtm7n8fOjB"
   },
   "source": [
    "### Performing ***Absolute Difference*** between **gray_frame_sample** and **gray_frame_median** to get the moving objects only, with the background removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "y808kSoDe0ne",
    "outputId": "5224d3b1-3828-4717-d60f-fdc60eeed5f6"
   },
   "outputs": [],
   "source": [
    "bg_removed_frame = cv2.absdiff(gray_frame_sample, gray_frame_median)\n",
    "plt.imshow(colorConvert(bg_removed_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MhBZVqJ4gfuy"
   },
   "source": [
    "Frame after background removal (ghost image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSKVV5dsgo_W"
   },
   "source": [
    "# **Blurring**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BBKMTTkiZjD"
   },
   "source": [
    "### Performing ***Gaussian Blur*** for noise reduction and to simplify edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "E4dJfIGxgsws",
    "outputId": "ad87f880-19c8-4a6f-8ba6-12975d9cff3a"
   },
   "outputs": [],
   "source": [
    "frame_blur = cv2.GaussianBlur(bg_removed_frame, (11,11), 0)\n",
    "plt.imshow(colorConvert(frame_blur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vScCdumjxZV"
   },
   "source": [
    "Frame after performing Gaussian Blur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLAtIutsj-Xz"
   },
   "source": [
    "# **Binarizing the image - Thresholding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnMDEmA6lckL"
   },
   "source": [
    "### Performing ***Threshold*** and ***OTSU Threshold*** to bring the moving objects out clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "osF24MRGkDz8",
    "outputId": "48ec0216-b784-4afa-a251-65334f7d3c5d"
   },
   "outputs": [],
   "source": [
    "ret, frame_threshold = cv2.threshold(frame_blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "plt.imshow(colorConvert(frame_threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qigx5-5IlW-z"
   },
   "source": [
    "Frame after thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT4G-R7-lyaU"
   },
   "source": [
    "# **Countour and Boundary Boxes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4L34mFhJokJ_"
   },
   "source": [
    "### Creating contours on the thresholded frame. Contours are ***curves joining continuous points in an image with same color intensity***. We shall use **cv2.RETR_EXTERNAL** to fing the extreme outer contours and **cv2.CHAIN_APPROX_SIMPLE** to remove the redundant points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuJoW4sAl5aI"
   },
   "outputs": [],
   "source": [
    "(contours, _ ) = cv2.findContours(frame_threshold.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b92dzcGqdk8"
   },
   "source": [
    "### Creating Bounding Boxes (rectangular) for identified contours and  display them on frame_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "KL8Rx7okq3un",
    "outputId": "cc0b4a34-b312-4757-daf7-3231504d34ee"
   },
   "outputs": [],
   "source": [
    "for i in contours:\n",
    "  x, y, width, height = cv2.boundingRect(i)\n",
    "  cv2.rectangle(frame_sample, (x,y), (x + width, y + height), (123,0,255), 2)\n",
    "plt.imshow(colorConvert(frame_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IuqpEVBnr6Qf"
   },
   "source": [
    "# **Compiling frames together for processing video**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYuskcoqs_Rc"
   },
   "source": [
    "### Declaring output video to be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QHy2e5tcs21z"
   },
   "outputs": [],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_writer = cv2.VideoWriter('Detect.avi', fourcc, 20.0, (640, 480))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJXef1--tcTR"
   },
   "source": [
    "### Creating cap and getting total frame count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "k5Ws5zw1tibZ",
    "outputId": "3f03c17c-2c4d-48ee-d3de-ba872674cdff"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('Media/vtest.avi')\n",
    "\n",
    "#Randomly selecting 30 frames\n",
    "frame_tot = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "frame_tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWnvLDgiuIFp"
   },
   "source": [
    "We have a total of 795 frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQt8fEt2uVYz"
   },
   "source": [
    "### Running a Loop to go through all frames and process the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vGtOjTBNuB5R"
   },
   "outputs": [],
   "source": [
    "frame_count = 0\n",
    "while (frame_count < frame_tot - 1):\n",
    "  frame_count+=1\n",
    "  ret, frame = cap.read()\n",
    "  # Converting frame to grayscale\n",
    "  gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "  # Calculating Absolute Difference between Current Frame and Median Frame\n",
    "  dframe = cv2.absdiff(gray_frame, gray_frame_median)\n",
    "  # Applying Gaussian Blur to reduce noise\n",
    "  blur_frame = cv2.GaussianBlur(dframe, (11,11), 0)\n",
    "  # Binarizing frame - Thresholding\n",
    "  ret, threshold_frame = cv2.threshold(blur_frame, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "  # Identifying Contours\n",
    "  (contours, _ ) = cv2.findContours(threshold_frame.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "  # Drawing Boundary Boxes for each Contour\n",
    "  for i in contours:\n",
    "    x, y, width, height = cv2.boundingRect(i)\n",
    "    cv2.rectangle(frame, (x,y), (x + width, y + height), (123,0,255), 2)\n",
    "  video_writer.write(cv2.resize(frame, (640,480)))\n",
    "\n",
    "# Releasing Video Object\n",
    "cap.release()\n",
    "video_writer.release()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Moving Object Detection in Videos.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
